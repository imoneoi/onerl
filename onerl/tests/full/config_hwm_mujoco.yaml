$global:
  profile: True
  profile_log_path: profile_log

  env:
    import: examples.mujoco_env
    name: create_mujoco_env
    params:
      name: HalfCheetahCustom-v3
    frame_stack: 1

  algorithm:
    import: onerl.algorithms
    name: HWMAlgorithm
    network:
      actor:
        import: onerl.networks
        name: MLP
        params:
          norm_type: none
          input_dims: 20
          num_hidden: [256, 256]
          output_dims: 6  # N(action)
      wm0:
        import: onerl.networks
        name: MLP
        params:
          norm_type: none
          input_dims: 26  # N(state) + N(action)
          num_hidden: [256, 256]
          output_dims: 22  # 2 + N(state)
      wm1:
        import: onerl.networks
        name: MLP
        params:
          norm_type: none
          input_dims: 26  # N(state) + N(action)
          num_hidden: [256, 256]
          output_dims: 22  # 2 + N(state)
      wm2:
        import: onerl.networks
        name: MLP
        params:
          norm_type: none
          input_dims: 26  # N(state) + N(action)
          num_hidden: [256, 256]
          output_dims: 22  # 2 + N(state)
      wm3:
        import: onerl.networks
        name: MLP
        params:
          norm_type: none
          input_dims: 26  # N(state) + N(action)
          num_hidden: [256, 256]
          output_dims: 22  # 2 + N(state)
      wm4:
        import: onerl.networks
        name: MLP
        params:
          norm_type: none
          input_dims: 26  # N(state) + N(action)
          num_hidden: [256, 256]
          output_dims: 22  # 2 + N(state)
      wm5:
        import: onerl.networks
        name: MLP
        params:
          norm_type: none
          input_dims: 26  # N(state) + N(action)
          num_hidden: [256, 256]
          output_dims: 22  # 2 + N(state)

    params:
      replay_buffer_size: 1000000
      batch_size: 256

  nodes:
    MetricNode:
      num: 1

$train:
  env:
    params:
      sleep_time: 0.02

  nodes:
    EnvNode:
      num: 1
    PolicyNode:
      num: 1
      batch_size: 1
      devices: [cpu]
    SchedulerNode:
      num: 1
    ReplayBufferNode:
      num: 1
    SamplerNode:
      num: 1
    OptimizerNode:
      num: 1
      update_interval: 0.5
      devices: [cuda:1]

$test:
  nodes:
    EnvNode:
      num: 1
    PolicyNode:
      num: 1
      batch_size: 1
      devices: [cpu]
      do_tick: False
      optimizer_namespace: $train
    SchedulerNode:
      num: 1
